Sys.setenv(SPARK_HOME = "/usr/local/Cellar/apache-spark/1.6.0/")
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "libexec", "R", "lib", ), .libPaths()))
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "libexec", "R", "lib"), .libPaths()))
.libPaths
.libPaths()
library(SparkR)
sparkR.init()
sparkR.init()
Sys.setenv(SPARK_HOME = "/usr/local/Cellar/apache-spark/1.6.0/libexec/")
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
sparkR.init()
sc <- sparkR.init(master = "local")
sc
sqlContext <- sparkRSQL.init(sc)
DF <- createDataFrame(sqlContext, faithful)
DF
head(DF)
localDF <- data.frame(name=c("John", "Smith", "Sarah"), age=c(19, 23, 18))
df <- createDataFrame(sqlContext, localDF)
df
printSchema(df)
path <- file.path(Sys.getenv("SPARK_HOME"), "examples/src/main/resources/people.json")
peopleDF <- jsonFile(sqlContext, path)
printSchema(peopleDF)
registerTempTable(peopleDF, "people")
teenagers <- sql(sqlContext, "SELECT name FROM people WHERE age >= 13 AND age <= 19")
teenagersLocalDF <- collect(teenagers)
print(teenagersLocalDF)
sparkR.stop()
data <- read.csv("~/Downloads/EURUSD-60-0_labeled.csv")
str(data)
data <- read.csv("~/Downloads/EURUSD-60-0_labeled.csv")
str(data)
ts <- read.csv("~/Downloads/EURUSD-60-0_labeled.csv")
plot.ts(ts$candle_open_timestamp)
plot.ts(ts$candle_open)
plot.ts(ts$candle_close)
plot.ts(ts$candle_open)
plot.ts(ts$candle_close)
plot.ts(ts$candle_close)
options(warn=-1)
library(hflights)
object.size(hflights)
library(data.table)
DT <- as.data.table(hflights)
DT
tables(DT)
DT
tables(DT)
DT[Month==10,mean(na.omit(AirTime)), by=UniqueCarrier]
object.size(DT)
DT[Month==10,mean(na.omit(AirTime)), by=UniqueCarrier]
DT <- as.data.table(hflights)
DT[3:5,]
DT[3:5,]
DT[UniqueCarrier="AA"]
DT[UniqueCarrier == "AA"]
DT[.N-1]
DT[.N-2]
DT[.N]
DT[.N-1]
DT[3:5,]
DT[UniqueCarrier == "AA"]
DT[.N-1]
names(DT)
DT[, mean(na.omit(Distance))]
DT[, mean(Distance)]
DT[, mean(ArrDelay)]
DT[, mean(na.omit(Distance))]
DT[, mean(Distance)]
?hflights
DT[, mean(DepDelay)]
DT[, mean(na.omit(DepDelay))]
DT[, .(mean(na.omit(DepDelay)), mean(na.omit(ArrDelay)))]
DT[, .(departure=mean(na.omit(DepDelay)), arrival=mean(na.omit(ArrDelay)))]
DT[, mean(na.omit(DepDelay)), by=UniqueCarrier]
DT[, mean(na.omit(DepDelay)), by=Origin]
DT[, mean(na.omit(DepDelay)), by=.(Origin, Weekdays)]
DT[, mean(na.omit(DepDelay)), by=.(Origin, DayOfWeek)]
DT[, mean(na.omit(DepDelay)), by=.(Origin, DayOfWeek < 6)]
DT[, mean(na.omit(DepDelay)), by=.(Origin, DayOfWeek >= 6)]
DT[, mean(na.omit(DepDelay)), by=.(Origin, Weekend = DayOfWeek >= 6)]
DT[, avg_delay = mean(na.omit(DepDelay)), by=.(Origin, Weekend = DayOfWeek >= 6)]
DT[, .(avg_delay = mean(na.omit(DepDelay))), by=.(Origin, Weekend = DayOfWeek >= 6)]
DT[, .(AVG_delay = mean(na.omit(DepDelay))), by=.(Origin, Weekend = DayOfWeek >= 6)]
names(DT)
str(DT)
DT$DepTime
cut(DT$DepTime)
?cut
cut(DT$DepTime, breaks=10)
DT[, DepTime := cut(DepTime, breaks=10)]
DT
DT <- as.data.table(hflights)
DT[, DepDelay := cut(DepDelay, breaks=10)]
DT
DT <- as.data.table(hflights)
DT[, Distance := cut(Distance, breaks=10)]
DT
tables(DT)
DT
DT[Distance,]
DT[, Distance]
DT
DT[, c("TaxiIn", "TaxiOut") := NULL]
DT
setkey(DT, Year)
tables(DT)
?tables
mb
tables()
tables()
DT[Year]
DT[Year,]
DT["Year"]
DT["Year", ]
DT
DT[2011]
DT[2012]
DT[2011]
DT
DT["2011",]
DT["2011"]
DT[2011]
DT[2013]
DT
tables()
setkey(DT, c(Year, Month, DayofMonth))
setkey(DT, c("Year", "Month", "DayofMonth"))
setkey(DT, Year, Month, DayofMonth))
setkey(DT, Year, Month, DayofMonth)
tables()
DT
DT[2011]
DT[.(2011, 1)]
DT[.(2011, 1, 1)]
DT[.(2011, 1, 12)]
DT[.(2011, c(3,4,5))]
DT[.(2011, c(1,2))]
DT[.(2011, c(1,2), sum(Cancelled))]
DT[.(2011, c(1,2), sum(Cancelled, na.rm=T))]
DT[.(2011, c(1,2), sum(Cancelled, na.rm=T))]
DT[.(2011, c(1,2)), sum(Cancelled, na.rm=T)]
DT[.(2011, c(1,2)), sum(Cancelled)]
DT[.(2011, c(3,4,5)), sum(Cancelled)]
DT[.(2013, c(3,4,5)), sum(Cancelled)]
DT[.(2012, c(3,4,5)), sum(Cancelled)]
DT[.(2011, c(3,4,5)), sum(Cancelled)]
DT[.(2012, c(3,4,5)), sum(na.omit(Cancelled))]
DT[.(2013, c(3,4,5)), sum(na.omit(Cancelled))]
DT[.(2014, c(3,4,5)), sum(na.omit(Cancelled))]
DT[.(2011, c(3,4,5)), sum(na.omit(Cancelled))]
DT[.(2011, c(3,4,5))]
DT[.(2012, c(3,4,5))]
DT[.(2012, c(1,2,3))]
DT[.(2012)]
DT[.(2011)]
identical(DT$Year)
unique(DT$Year)
setkey(DT, Year, Month)
tables()
DT[.(2011, c(3,4,5)), sum(Cancelled)]
DT[.(2011, c(3,4,5)), sum(Cancelled),  by=.EACHI]
setkey(DT, Year, Month)
DT[.(2011, c(3,4,5)), sum(Cancelled)]
DT[,.SD[.N], by=.(Year, Month)]
DT[,.SD[.I], by=.(Year, Month)]
DT[,.I, by=.(Year, Month)]
DT[,.SD[.N], by=.(Year, Month)]
DT[, Count := .SD[.N], by=.(Year, Month)]
DT
DT$Count
unique(DT$Count)
DT[, Count := lapply(.SD, mean), by=.(Year, Month)]
?mean
names(DT)
DT[, lapply(.SD[,.(AirTime, ArrDelay, DepDelay)], mean), by=.(Year, Month)]
DT[, lapply(.SD[,.(AirTime, ArrDelay, DepDelay)], mean, na.rm=T), by=.(Year, Month)]
DT[, lapply(.SD[.(AirTime, ArrDelay, DepDelay)], mean, na.rm=T), by=.(Year, Month)]
DT[, lapply(.SD[, .(AirTime, ArrDelay, DepDelay)], mean, na.rm=T), by=.(Year, Month)]
DT[, .(AirTime, ArrDelay, DepDelay), by=.(Year, Month)]
DT[, mean(.(AirTime, ArrDelay, DepDelay)), by=.(Year, Month)]
DT[, lapply(.SD[, .(AirTime, ArrDelay, DepDelay)], mean, na.rm=T), by=.(Year, Month)]
DT[, lapply(.SD[, c(AirTime, ArrDelay, DepDelay)], mean, na.rm=T), by=.(Year, Month)]
DT[, lapply(.SD[, .(AirTime, ArrDelay, DepDelay)], mean, na.rm=T), by=.(Year, Month)]
DT[.(2011), lapply(.SD[, .(AirTime, ArrDelay, DepDelay)], mean, na.rm=T)]
DT[, lapply(.SD[, .(AirTime, ArrDelay, DepDelay)], mean, na.rm=T), by=c(Year, Month)]
DT[, lapply(.SD[, .(AirTime, ArrDelay, DepDelay)], mean, na.rm=T), by=c("Year", "Month")]
DT[, lapply(.SD[, .(AirTime, ArrDelay, DepDelay)], mean, na.rm=T), by=.(Year, Month)]
history()
?history
?hist
DT <- as.data.table(hflights)
DT <- as.data.table(hflights)
DT
DT[, Discrete_Distance  := cut(Distance, breaks=10)]
DT
DT[, Discrete_Distance  := cut(Distance, breaks=50)]
DT
DT[, Discrete_Distance  := cut(Distance, breaks=20)]
levels(DT$Discrete_Distance)
DT[, ActualElapsedTime := ActualElapsedTime / 60]
DT
DT[, lapply(.SD[, .(AirTime, ArrDelay, DepDelay)], mean, na.rm=T), by=.(Year, Month)]
DT[, lapply(.SD[, .(AirTime, ArrDelay, DepDelay)], mean, na.rm=T), by=.(Year, Month, Weekend = DayOfWeek < 6)]
DT[, lapply(.SD[, .(AirTime)], mean, na.rm=T), by=.(Year, Month, Weekend = DayOfWeek < 6)]
DT[, lapply(.SD[, .(AirTime)], mean, na.rm=T), by=.(Year, Month, Weekend = DayOfWeek < 6)]
DT[, lapply(.SD[, .(AirTime)], mean, na.rm=T), by=.(Year, Month, Weekend = DayOfWeek < 6)]
DT[.(2011, 1), lapply(.SD[, .(AirTime)], mean, na.rm=T), by=.(Year, Weekend = DayOfWeek < 6)]
DT[.(2011, 1), lapply(.SD[, .(AirTime)], mean, na.rm=T), by=.(Weekend = DayOfWeek < 6)]
tables()
setkey(DT, Year, Month)
DT[.(2011, 1), lapply(.SD[, .(AirTime)], mean, na.rm=T), by=.(Weekend = DayOfWeek < 6)]
DT[.(2011), lapply(.SD[, .(AirTime)], mean, na.rm=T), by=.(Weekend = DayOfWeek < 1)]
DT[2011, lapply(.SD[, .(AirTime)], mean, na.rm=T), by=.( = DayOfWeek == 1)]
DT[2011, lapply(.SD[, .(AirTime)], mean, na.rm=T), by=.(Monday = DayOfWeek == 1)]
DT[2011, lapply(.SD[, .(AirTime)], mean, na.rm=T), by=.(Monday = DayOfWeek == 2)]
DT[2011, lapply(.SD[, .(AirTime)], mean, na.rm=T)]
DT[.(2011, 1:12), lapply(.SD[, .(AirTime)], mean, na.rm=T)]
DT[2011, lapply(.SD[, .(AirTime)], mean, na.rm=T), by=.(DayOfWeek)]
DT[ ,lapply(.SD[, .(AirTime)], mean, na.rm=T), by=.(Year, DayOfWeek)]
DT[ ,lapply(.SD[, .(DepTime)], mean, na.rm=T), by=.(Year, DayOfWeek)]
?hflights
DT[ ,lapply(.SD[, .(ArrTime)], mean, na.rm=T), by=.(Year, DayOfWeek)]
DT[ ,lapply(.SD[, .(DepTime)], mean, na.rm=T), by=.(Year, DayOfWeek)]
DT[ , mean(DepTime, na.rm=T), by=.(Year, DayOfWeek)]
DT[ , min(DepTime, na.rm=T), by=.(Year, DayOfWeek)]
DT[ , max(DepTime, na.rm=T), by=.(Year, DayOfWeek)]
DT[ , max(DepTime, na.rm=T), by=.(Year, UniqueCarrier, DayOfWeek)]
DT[ ,lapply(.SD[, .(ArrTime)], max, na.rm=T), by=.(Year, DayOfWeek)]
DT[ ,lapply(.SD[, .(ArrTime)], max, na.rm=T), by=.(Year, DayOfWeek)]
DT[ , mean(DepTime, na.rm=T), by=.(Year, UniqueCarrier, DayOfWeek)]
DT[ , mean(DepTime, na.rm=T), by=.(Year, UniqueCarrier)]
DT[ , mean(ArrDelay, na.rm=T), by=.(Year, UniqueCarrier)]
DT[ , mean(ArrDelay, na.rm=T), by=.(UniqueCarrier)]
DT[ , mean(ArrDelay, na.rm=T), by=.(Year, UniqueCarrier)]
DT[, mean(ArrDelay, na.rm=T), by=.(Year, UniqueCarrier)]
DT[, order(mean(ArrDelay, na.rm=T)), by=.(Year, UniqueCarrier)]
DT[, mean(ArrDelay, na.rm=T), by=.(Year, UniqueCarrier)]
DT[ , mean(ArrDelay, na.rm=T), by=.(UniqueCarrier)]
DT[ , max(DepDelay, na.rm=T), by=.(Year, UniqueCarrier, DayOfWeek)]
DT[ , max(DepDelay, na.rm=T), by=.(Year, DayOfWeek)]
DT[ , mean(DepDelay, na.rm=T), by=.(Year, DayOfWeek)]
DT[Origin == "IAH", mean(DepDelay, na.rm=T), by=.(Year, DayOfWeek)]
DT[Origin == "IAH", mean(DepDelay, na.rm=T), by=.(DayOfWeek)]
Sys.setenv(SPARK_HOME = "/usr/local/Cellar/apache-spark/1.6.0/libexec/")
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
sparkR.init()
?sparkR.init
sparkR.stop()
sparkR.init(master="local[2]")
sparkR.stop()
Sys.setenv(SPARK_HOME = "/usr/local/Cellar/apache-spark/1.6.1/libexec/")
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
sparkR.init(master="local[2]")
sparkR.stop()
sc <- sparkR.init(master="local[2]")
sparkR.stop()
sc <- sparkR.init(master="local")
sc
sqlc <- sparkRSQL.init(sc)
shakespeare = read.text(sqlContext, "assets/sh.txt")
shakespeare = sparkR.read.text(sqlContext, "assets/sh.txt")
sparkR.stop()
Sys.setenv(SPARK_HOME = "~/Downloads/spark-1.6.2-bin-hadoop2.6")
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
sc <- sparkR.init(master="local")
Sys.setenv(SPARK_HOME = "/Users/quetzal/Downloads/spark-1.6.2-bin-hadoop2.6")
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
sc <- sparkR.init(master="local")
sqlc <- sparkRSQL.init(sc)
?read.df()
?read.text
shakespeare = read.text(sqlc, "assets/sh.txt")
sparkR.stop()
Sys.setenv(SPARK_HOME = "/Users/quetzal/Downloads/spark-1.6.2-bin-hadoop2.6")
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
sc <- sparkR.init(master="local")
sqlc <- sparkRSQL.init(sc)
sqlc
shakespeare <- read.text(sqlc, "assets/sh.txt")
read.text()
?read.text()
shakespeare
?take()
?take
take(shakespeare, 15)
shakespeare
sparkR.stop()
Sys.setenv(SPARK_HOME = "/Users/quetzal/Downloads/spark-1.6.2-bin-hadoop2.6")
Sys.setenv(SPARK_WORKER_INSTANCES = 2)
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
sc <- sparkR.init(master="local")
sparkR.stop()
sc <- sparkR.init(master="local[4]")
sqlc <- sparkRSQL.init(sc)
shakespeare <- read.text(sqlc, "assets/sh.txt")
setwd("~/repos/da-workshops/bigData/assets/sh.txt")
setwd("~/repos/da-workshops/bigData/")
shakespeare <- read.text(sqlc, "assets/sh.txt")
take(shakespeare, 15)
print(take(shakespeare, 15))
options(warn=-1)
sparkR.stop()
library(SparkR)
sc <- sparkR.init(master="local[2]")
sqlc <- sparkRSQL.init(sc)
shakespeare <- read.text(sqlc, "assets/sh.txt")
print(take(shakespeare, 15))
setwd("~/repos/da-workshops/bigData/")
Sys.setenv(SPARK_HOME = "/Users/quetzal/Downloads/spark-1.6.2-bin-hadoop2.6")
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
sc <- sparkR.init(master="local[2]")
sqlc <- sparkRSQL.init(sc)
setwd("~/repos/da-workshops/bigData/")
shakespeare <- read.text(sqlc, "assets/sh.txt")
print(take(shakespeare, 15))
count(shakespeare)
?map()
shakespeare$value
?head()
?head()
?select()
summary(shakespeare)
print(summary(shakespeare))
describe(shakespeare)
names(shakespeare)
length(shakespeare)
select(shakespeare, "value")
?showDF()
Sys.setenv(SPARK_HOME = "/Users/quetzal/Downloads/spark-1.6.2-bin-hadoop2.6")
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
sc <- sparkR.init(master="local[2]")
sqlc <- sparkRSQL.init(sc)
sparkR.stop()
Sys.setenv(SPARK_HOME = "/Users/quetzal/Downloads/spark-1.6.2-bin-hadoop2.6")
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
library(SparkR)
sc <- sparkR.init(master="local[2]")
sqlc <- sparkRSQL.init(sc)
setwd("~/repos/da-workshops/bigData/")
shakespeare <- read.text(sqlc, "assets/sh.txt")
print(take(shakespeare, 15))
?showDF()
agg(shakespeare, function(x) len(x))
num_chars = SparkR:::map(shakespeare, function(x) length(x))
num_chars <- SparkR:::map(shakespeare, function(x) length(x))
sparkR.stop()
library(SparkR)
sc <- sparkR.init(master="local[2]")
sqlc <- sparkRSQL.init(sc)
setwd("~/repos/da-workshops/bigData/")
shakespeare <- read.text(sqlc, "assets/sh.txt")
# Print out frist 15 lines
print(take(shakespeare, 15))
# How many lines do we have?
count(shakespeare)
?lapply()
d <- lapply(shakespeare, function(x) base::length(x))
num_chars <- SparkR:::map(shakespeare, function(x) base::length(x))
df2 <- agg(shakespeare, avg = "avg")
df2 <- agg(shakespeare, value = "avg")
print(df2)
take(df2)
collect(df2)
num_chars
take(num_chars)
collect(num_chars)
length("collect(num_chars)")
num_chars <- SparkR:::map(shakespeare, function(x) nchar(x))
head(num_chars)
take(num_chars)
num_chars
library(hflights)
df <- createDataFrame(sqlContext, hflights)
sqlContext <- sparkRSQL.init(sc)
df <- createDataFrame(sqlContext, hflights)
head(df, 10)
count(df)
dim(df)
